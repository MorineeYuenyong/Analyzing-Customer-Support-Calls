{"cells":[{"source":"<p align=\"center\" width=\"100%\">\n    <img width=\"40%\" src=\"customer_support_icon.JPG\"> \n</p>\n\nA retail company is on a transformative journey, aiming to elevate their customer services through cutting-edge advancements in Speech Recognition and Natural Language Processing (NLP). As the machine learning engineer for this initiative, you are tasked with developing functionalities that not only convert customer support audio calls into text but also explore methodologies to extract insights from transcribed texts.\n\nIn this dynamic project, we leverage the power of `SpeechRecognition`, `Pydub`, and `spaCy` – three open-source packages that form the backbone of your solution. Your objectives are:\n  - Transcribe a sample customer audio call, stored at `sample_customer_call.wav`, to showcase the power of open-source speech recognition technology.\n  - Analyze sentiment, identify common named entities, and enhance user experience by searching for the most similar customer calls based on a given query from a subset of their pre-transcribed call data, stored at `customer_call_transcriptions.csv`.\n\nThis project is an opportunity to unlock the potential of machine learning to revolutionize customer support. Let's delve into the interplay between technology and service excellence.","metadata":{},"id":"d5e81b43-ccfd-4fc6-902c-59cd49aa9913","cell_type":"markdown"},{"source":"!pip install SpeechRecognition\n!pip install pydub\n!pip install spacy\n!python3 -m spacy download en_core_web_sm","metadata":{"executionCancelledAt":null,"executionTime":20456,"lastExecutedAt":1735417978909,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"!pip install SpeechRecognition\n!pip install pydub\n!pip install spacy\n!python3 -m spacy download en_core_web_sm","outputsMetadata":{"0":{"height":613,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false},"lastExecutedByKernel":"a79b75ba-aa11-4af1-87ee-0b3cb95c46a0"},"id":"d0f1598e-18a8-45d5-8387-bf2f5ce4ffd6","cell_type":"code","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nCollecting SpeechRecognition\n  Downloading SpeechRecognition-3.10.4-py2.py3-none-any.whl.metadata (28 kB)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.8/dist-packages (from SpeechRecognition) (2.31.0)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from SpeechRecognition) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.8)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.25.8)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.26.0->SpeechRecognition) (2019.11.28)\nDownloading SpeechRecognition-3.10.4-py2.py3-none-any.whl (32.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m147.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: SpeechRecognition\nSuccessfully installed SpeechRecognition-3.10.4\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\nDefaulting to user installation because normal site-packages is not writeable\nCollecting pydub\n  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\nDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\nInstalling collected packages: pydub\nSuccessfully installed pydub-0.25.1\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: spacy in /usr/local/lib/python3.8/dist-packages (3.6.1)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.9)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.7)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.8)\nRequirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.8/dist-packages (from spacy) (8.1.12)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.4.7)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.9)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.9.0)\nRequirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.2)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (4.64.0)\nRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.23.2)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.31.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.10.12)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.1.2)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy) (65.6.3)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (23.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.3.0)\nRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.8)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.3)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy) (2.1.1)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\nDefaulting to user installation because normal site-packages is not writeable\nCollecting en-core-web-sm==3.6.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m151.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from en-core-web-sm==3.6.0) (3.6.1)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.9)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.8)\nRequirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.7)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.9)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\nRequirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.2)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.64.0)\nRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.2)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.12)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (65.6.3)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\nRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.8)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.25.8)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2019.11.28)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.3)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.1)\nInstalling collected packages: en-core-web-sm\nSuccessfully installed en-core-web-sm-3.6.0\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n"}]},{"source":"import pandas as pd\n\nimport nltk\nnltk.download('vader_lexicon')\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nimport speech_recognition as sr\nfrom pydub import AudioSegment\n\nimport spacy","metadata":{"executionCancelledAt":null,"executionTime":10105,"lastExecutedAt":1735417989016,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import pandas as pd\n\nimport nltk\nnltk.download('vader_lexicon')\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nimport speech_recognition as sr\nfrom pydub import AudioSegment\n\nimport spacy","outputsMetadata":{"0":{"height":59,"type":"stream"}},"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedByKernel":"a79b75ba-aa11-4af1-87ee-0b3cb95c46a0"},"id":"d6f3dd61-8c75-48d4-b2a5-79cd0b444ddb","cell_type":"code","execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":"[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /home/repl/nltk_data...\n"}]},{"source":"# Task 1 - Speech to Text: แปลงไฟล์เสียงจาก audio call (sample_customer_call.wav) เป็นข้อความ และเก็บผลลัพธ์ใน transcribed_text\n\n# สร้าง object recognizer สำหรับแปลงเสียงเป็นข้อความ\nrecognizer = sr.Recognizer()\n\n# แปลงไฟล์เสียงเป็นข้อมูลเสียง\ntranscribe_audio_file = sr.AudioFile(\"sample_customer_call.wav\")\nwith transcribe_audio_file as source:\n    transcribe_audio = recognizer.record(source)\n\n# แปลงข้อมูลเสียงเป็นข้อความโดยใช้ Google Speech Recognition API\ntranscribed_text = recognizer.recognize_google(transcribe_audio)\n\n# แสดงข้อความที่แปลงจากเสียง\nprint(\"ข้อความที่แปลงจากเสียง: \", transcribed_text)\n\n# Task 1 - Speech to Text: เก็บข้อมูลสถิติของไฟล์เสียง เช่น จำนวนช่องเสียง (channels), ความกว้างของตัวอย่าง (sample width), และอัตราเฟรม (frame rate)\n\n# ตรวจสอบจำนวนช่องเสียง (channels) และอัตราเฟรม (frame rate) ของไฟล์เสียง\naudio_segment = AudioSegment.from_file(\"sample_customer_call.wav\")\nnumber_channels = audio_segment.channels\nframe_rate = audio_segment.frame_rate\n\n# แสดงจำนวนช่องเสียงและอัตราเฟรมของไฟล์เสียง\nprint(\"จำนวนช่องเสียง: \", number_channels)\nprint(\"อัตราเฟรม: \", frame_rate)\n","metadata":{"executionCancelledAt":null,"executionTime":1427,"lastExecutedAt":1735417990445,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Task 1 - Speech to Text: แปลงไฟล์เสียงจาก audio call (sample_customer_call.wav) เป็นข้อความ และเก็บผลลัพธ์ใน transcribed_text\n\n# สร้าง object recognizer สำหรับแปลงเสียงเป็นข้อความ\nrecognizer = sr.Recognizer()\n\n# แปลงไฟล์เสียงเป็นข้อมูลเสียง\ntranscribe_audio_file = sr.AudioFile(\"sample_customer_call.wav\")\nwith transcribe_audio_file as source:\n    transcribe_audio = recognizer.record(source)\n\n# แปลงข้อมูลเสียงเป็นข้อความโดยใช้ Google Speech Recognition API\ntranscribed_text = recognizer.recognize_google(transcribe_audio)\n\n# แสดงข้อความที่แปลงจากเสียง\nprint(\"ข้อความที่แปลงจากเสียง: \", transcribed_text)\n\n# Task 1 - Speech to Text: เก็บข้อมูลสถิติของไฟล์เสียง เช่น จำนวนช่องเสียง (channels), ความกว้างของตัวอย่าง (sample width), และอัตราเฟรม (frame rate)\n\n# ตรวจสอบจำนวนช่องเสียง (channels) และอัตราเฟรม (frame rate) ของไฟล์เสียง\naudio_segment = AudioSegment.from_file(\"sample_customer_call.wav\")\nnumber_channels = audio_segment.channels\nframe_rate = audio_segment.frame_rate\n\n# แสดงจำนวนช่องเสียงและอัตราเฟรมของไฟล์เสียง\nprint(\"จำนวนช่องเสียง: \", number_channels)\nprint(\"อัตราเฟรม: \", frame_rate)\n","outputsMetadata":{"0":{"height":80,"type":"stream"}},"lastExecutedByKernel":"a79b75ba-aa11-4af1-87ee-0b3cb95c46a0"},"id":"250524c2-1bd3-4ff8-a224-8fa007566c1b","cell_type":"code","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":"ข้อความที่แปลงจากเสียง:  hello I'm experiencing an issue with your product I'd like to speak to someone about a replacement\nจำนวนช่องเสียง:  1\nอัตราเฟรม:  44100\n"}]},{"source":"# Task 2 - Sentiment Analysis: วิเคราะห์ความคิดเห็นจากข้อความในไฟล์ customer_call_transcriptions.csv โดย Vader จากไลบรารี nltk และมีการเพิ่มคอลัมน์ใหม่ใน DataFrame สำหรับเก็บผลลัพธ์ความคิดเห็น\n\ndf = pd.read_csv(\"customer_call_transcriptions.csv\")\n\nsid = SentimentIntensityAnalyzer()\n\n# ฟังก์ชันวิเคราะห์ความคิดเห็น\ndef find_sentiment(text):\n    scores = sid.polarity_scores(text)\n    compound_score = scores['compound']\n\n    if compound_score >= 0.05:\n        return 'positive'\n    elif compound_score <= -0.05:\n        return 'negative'\n    else:\n        return 'neutral'\n\ndf['sentiment_predicted'] = df.apply(lambda row: find_sentiment(row[\"text\"]), axis = 1)\n\n# Task 2 - Sentiment Analysis: คำนวณ True Positive\ntrue_positive = len(df.loc[(df['sentiment_predicted'] == df['sentiment_label']) &\n                (df['sentiment_label'] == 'positive')])\n\nprint(\"True positives: \", true_positive)","metadata":{"executionCancelledAt":null,"executionTime":68,"lastExecutedAt":1735417990514,"lastExecutedByKernel":"a79b75ba-aa11-4af1-87ee-0b3cb95c46a0","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Task 2 - Sentiment Analysis: วิเคราะห์ความคิดเห็นจากข้อความในไฟล์ customer_call_transcriptions.csv โดย Vader จากไลบรารี nltk และมีการเพิ่มคอลัมน์ใหม่ใน DataFrame สำหรับเก็บผลลัพธ์ความคิดเห็น\n\ndf = pd.read_csv(\"customer_call_transcriptions.csv\")\n\nsid = SentimentIntensityAnalyzer()\n\n# ฟังก์ชันวิเคราะห์ความคิดเห็น\ndef find_sentiment(text):\n    scores = sid.polarity_scores(text)\n    compound_score = scores['compound']\n\n    if compound_score >= 0.05:\n        return 'positive'\n    elif compound_score <= -0.05:\n        return 'negative'\n    else:\n        return 'neutral'\n\ndf['sentiment_predicted'] = df.apply(lambda row: find_sentiment(row[\"text\"]), axis = 1)\n\n# Task 2 - Sentiment Analysis: คำนวณ True Positive\ntrue_positive = len(df.loc[(df['sentiment_predicted'] == df['sentiment_label']) &\n                (df['sentiment_label'] == 'positive')])\n\nprint(\"True positives: \", true_positive)","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"58d88b48-551a-47a5-baba-b11706e752a2","outputs":[{"output_type":"stream","name":"stdout","text":"True positives:  2\n"}],"execution_count":4},{"source":"# Task 3 - Named Entity Recognition: ค้นหา Named Entities จากข้อความในแต่ละแถวของ DataFrame และจัดเก็บผลลัพธ์ไว้ในคอลัมน์ใหม่\n\nnlp = spacy.load(\"en_core_web_sm\")\n\n# ฟังก์ชันสำหรับดึง Named Entities (NER) จากข้อความ\ndef extract_entities(text):\n    doc = nlp(text)\n    entities = [ent.text for ent in doc.ents]\n    return entities\n\n# ใช้ NER กับคอลัมน์ข้อความทั้งหมดใน DataFrame\ndf['named_entities'] = df['text'].apply(extract_entities)\n\n# ทำให้รายการ named entities เป็นลิสต์เดียว (flatten)\nall_entities = [ent for entities in df['named_entities'] for ent in entities]\n\n# สร้าง DataFrame ที่นับจำนวน named entities\nentities_df = pd.DataFrame(all_entities, columns=['entity'])\nentities_counts = entities_df['entity'].value_counts().reset_index()\nentities_counts.columns = ['entity', 'count']\n\n# ดึง Named Entity ที่พบมากที่สุด\nmost_freq_ent = entities_counts[\"entity\"].iloc[0]\nprint(\"Most frequent entity: \", most_freq_ent)\n","metadata":{"executionCancelledAt":null,"executionTime":1124,"lastExecutedAt":1735417991638,"lastExecutedByKernel":"a79b75ba-aa11-4af1-87ee-0b3cb95c46a0","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Task 3 - Named Entity Recognition: ค้นหา Named Entities จากข้อความในแต่ละแถวของ DataFrame และจัดเก็บผลลัพธ์ไว้ในคอลัมน์ใหม่\n\nnlp = spacy.load(\"en_core_web_sm\")\n\n# ฟังก์ชันสำหรับดึง Named Entities (NER) จากข้อความ\ndef extract_entities(text):\n    doc = nlp(text)\n    entities = [ent.text for ent in doc.ents]\n    return entities\n\n# ใช้ NER กับคอลัมน์ข้อความทั้งหมดใน DataFrame\ndf['named_entities'] = df['text'].apply(extract_entities)\n\n# ทำให้รายการ named entities เป็นลิสต์เดียว (flatten)\nall_entities = [ent for entities in df['named_entities'] for ent in entities]\n\n# สร้าง DataFrame ที่นับจำนวน named entities\nentities_df = pd.DataFrame(all_entities, columns=['entity'])\nentities_counts = entities_df['entity'].value_counts().reset_index()\nentities_counts.columns = ['entity', 'count']\n\n# ดึง Named Entity ที่พบมากที่สุด\nmost_freq_ent = entities_counts[\"entity\"].iloc[0]\nprint(\"Most frequent entity: \", most_freq_ent)\n","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"75fe56af-eacc-4fe8-af94-505fd153604d","outputs":[{"output_type":"stream","name":"stdout","text":"Most frequent entity:  yesterday\n"}],"execution_count":5},{"source":"# Task 4 - Find most similar text: ค้นหาลิสต์ของข้อความจากลูกค้าที่ร้องเรียนเกี่ยวกับ \"wrong package delivery\" โดยคำนวณคะแนนความเหมือน (similarity score) ของแต่ละข้อความใน DataFrame เทียบกับข้อความต้นแบบ \"wrong package delivery\" โดยใช้spaCy\n\nnlp = spacy.load(\"en_core_web_sm\")\n\n# ประมวลผลข้อความในคอลัมน์ text\ndf['processed_text'] = df['text'].apply(lambda text: nlp(text))\n\n# ข้อความที่ต้องการค้นหา (Input Query)\ninput_query = \"wrong package delivery\"\nprocessed_query = nlp(input_query)\n\n# คำนวณคะแนนความเหมือน (Similarity Score) และจัดเรียง DataFrame ตามคะแนน\ndf['similarity'] = df['processed_text'].apply(lambda text: processed_query.similarity(text))\ndf = df.sort_values(by='similarity', ascending=False)\n\n# ค้นหาข้อความที่เหมือนที่สุด\nmost_similar_text = df[\"text\"].iloc[0]\nprint(\"Most similar text: \", most_similar_text)\n","metadata":{"executionCancelledAt":null,"executionTime":1082,"lastExecutedAt":1735417992720,"lastExecutedByKernel":"a79b75ba-aa11-4af1-87ee-0b3cb95c46a0","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Task 4 - Find most similar text: ค้นหาลิสต์ของข้อความจากลูกค้าที่ร้องเรียนเกี่ยวกับ \"wrong package delivery\" โดยคำนวณคะแนนความเหมือน (similarity score) ของแต่ละข้อความใน DataFrame เทียบกับข้อความต้นแบบ \"wrong package delivery\" โดยใช้spaCy\n\nnlp = spacy.load(\"en_core_web_sm\")\n\n# ประมวลผลข้อความในคอลัมน์ text\ndf['processed_text'] = df['text'].apply(lambda text: nlp(text))\n\n# ข้อความที่ต้องการค้นหา (Input Query)\ninput_query = \"wrong package delivery\"\nprocessed_query = nlp(input_query)\n\n# คำนวณคะแนนความเหมือน (Similarity Score) และจัดเรียง DataFrame ตามคะแนน\ndf['similarity'] = df['processed_text'].apply(lambda text: processed_query.similarity(text))\ndf = df.sort_values(by='similarity', ascending=False)\n\n# ค้นหาข้อความที่เหมือนที่สุด\nmost_similar_text = df[\"text\"].iloc[0]\nprint(\"Most similar text: \", most_similar_text)\n","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"e502011d-848c-4543-a8b2-2302ae17eac7","outputs":[{"output_type":"stream","name":"stdout","text":"Most similar text:  wrong package delivered\n"}],"execution_count":6}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}